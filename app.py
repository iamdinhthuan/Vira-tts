import time
import torch
import gradio as gr
from mira.model_novasr import MiraTTSNovaSR
from mira.model import MiraTTS
from mira.utils import split_text

# Load models globally (load once at startup)
MODEL_PATH = 'outputs_vi/checkpoint-25000'

print("Loading MiraTTS with NovaSR upsampler...")
mira_tts_novasr = MiraTTSNovaSR(MODEL_PATH)
print("NovaSR model loaded!")

print("Loading MiraTTS with FlashSR upsampler...")
mira_tts_flashsr = MiraTTS(MODEL_PATH)
print("FlashSR model loaded!")

SAMPLE_RATE = 48000


def generate_speech(text: str, reference_audio: str, upsampler: str):
    """Generate speech from text using reference audio for voice cloning."""

    if not text.strip():
        return None, "Vui l√≤ng nh·∫≠p vƒÉn b·∫£n."

    if reference_audio is None:
        return None, "Vui l√≤ng upload file audio tham chi·∫øu."

    try:
        # Select model based on upsampler choice
        if upsampler == "NovaSR (50KB, 3600x realtime)":
            mira_tts = mira_tts_novasr
            upsampler_name = "NovaSR"
        else:
            mira_tts = mira_tts_flashsr
            upsampler_name = "FlashSR"

        # Encode reference audio
        context_tokens = mira_tts.encode_audio(reference_audio)

        # Split text into sentences
        sentences = split_text(text)

        # Generate audio and measure time
        start_time = time.time()

        if len(sentences) == 1:
            # Single sentence - use generate
            audio = mira_tts.generate(sentences[0], context_tokens)
        else:
            # Multiple sentences - use batch_generate
            audio = mira_tts.batch_generate(sentences, [context_tokens])

        inference_time = time.time() - start_time

        # Calculate RTF
        audio_np = audio.float().cpu().numpy()
        audio_duration = len(audio_np) / SAMPLE_RATE
        rtf = inference_time / audio_duration

        # Create stats message
        stats = f"üîß {upsampler_name} | üìù S·ªë c√¢u: {len(sentences)} | ‚è±Ô∏è Inference: {inference_time:.2f}s | üéµ Audio: {audio_duration:.2f}s | üìä RTF: {rtf:.4f}"

        return (SAMPLE_RATE, audio_np), stats

    except Exception as e:
        return None, f"L·ªói: {str(e)}"


# Create Gradio interface
with gr.Blocks(title="Vira-TTS Vietnamese", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # üéôÔ∏è Vira-TTS Vietnamese
    ### Text-to-Speech v·ªõi Voice Cloning

    Upload m·ªôt file audio tham chi·∫øu ƒë·ªÉ clone gi·ªçng n√≥i, sau ƒë√≥ nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ t·∫°o audio.

    | Upsampler | Speed | Size |
    |-----------|-------|------|
    | **NovaSR** | 3600x realtime | 50KB |
    | FlashSR | 14x realtime | 1GB |
    """)

    with gr.Row():
        with gr.Column(scale=1):
            text_input = gr.Textbox(
                label="VƒÉn b·∫£n",
                placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát t·∫°i ƒë√¢y...",
                lines=5
            )
            reference_audio = gr.Audio(
                label="Audio tham chi·∫øu (ƒë·ªÉ clone gi·ªçng)",
                type="filepath"
            )
            upsampler_choice = gr.Radio(
                label="Upsampler",
                choices=["NovaSR (50KB, 3600x realtime)", "FlashSR (1GB, 14x realtime)"],
                value="NovaSR (50KB, 3600x realtime)"
            )
            generate_btn = gr.Button("üéµ T·∫°o Audio", variant="primary", size="lg")

        with gr.Column(scale=1):
            output_audio = gr.Audio(
                label="Audio ƒë·∫ßu ra",
                type="numpy"
            )
            stats_output = gr.Textbox(
                label="Th·ªëng k√™",
                interactive=False
            )

    # Example texts (click to fill)
    gr.Markdown("### üìù V√≠ d·ª• vƒÉn b·∫£n:")
    with gr.Row():
        gr.Button("Xin ch√†o, t√¥i l√† tr·ª£ l√Ω ·∫£o.").click(
            fn=lambda: "Xin ch√†o, t√¥i l√† tr·ª£ l√Ω ·∫£o MiraTTS.",
            outputs=[text_input]
        )
        gr.Button("Th·ªùi ti·∫øt h√¥m nay").click(
            fn=lambda: "H√¥m nay th·ªùi ti·∫øt r·∫•t ƒë·∫πp, ch√∫ng ta ƒëi d·∫°o nh√©!",
            outputs=[text_input]
        )
        gr.Button("C√¥ng ngh·ªá AI").click(
            fn=lambda: "C√¥ng ngh·ªá tr√≠ tu·ªá nh√¢n t·∫°o ƒëang ph√°t tri·ªÉn r·∫•t nhanh ch√≥ng.",
            outputs=[text_input]
        )

    # Event handler
    generate_btn.click(
        fn=generate_speech,
        inputs=[text_input, reference_audio, upsampler_choice],
        outputs=[output_audio, stats_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)

