import time
import os
import torch
import gradio as gr
from huggingface_hub import snapshot_download
from mira.model import MiraTTS
from mira.utils import split_text

# Model config
HF_MODEL_ID = "dolly-vn/Vira-TTS"
MODEL_PATH = "model_pretrained"

def download_model_if_needed():
    """Download model from HuggingFace if not exists locally."""
    if not os.path.exists(MODEL_PATH) or not os.listdir(MODEL_PATH):
        print(f"ğŸ“¥ Downloading model from HuggingFace: {HF_MODEL_ID}...")
        snapshot_download(
            repo_id=HF_MODEL_ID,
            local_dir=MODEL_PATH,
            local_dir_use_symlinks=False
        )
        print("âœ… Model downloaded!")
    else:
        print(f"âœ… Model found at: {MODEL_PATH}")

# Download model if needed
download_model_if_needed()

print("ğŸ”„ Loading Vira-TTS...")
mira_tts = MiraTTS(MODEL_PATH)
print("âœ… Model loaded!")

SAMPLE_RATE = 48000


def generate_speech(text: str, reference_audio: str):
    """Generate speech from text using reference audio for voice cloning."""

    if not text.strip():
        return None, "Vui lÃ²ng nháº­p vÄƒn báº£n."

    if reference_audio is None:
        return None, "Vui lÃ²ng upload file audio tham chiáº¿u."

    try:
        # Encode reference audio
        context_tokens = mira_tts.encode_audio(reference_audio)

        # Split text into sentences
        sentences = split_text(text)

        # Generate audio and measure time
        start_time = time.time()

        if len(sentences) == 1:
            # Single sentence - use generate
            audio = mira_tts.generate(sentences[0], context_tokens)
        else:
            # Multiple sentences - use batch_generate
            audio = mira_tts.batch_generate(sentences, [context_tokens])

        inference_time = time.time() - start_time

        # Calculate RTF
        audio_np = audio.float().cpu().numpy()
        audio_duration = len(audio_np) / SAMPLE_RATE
        rtf = inference_time / audio_duration

        # Create stats message
        stats = f"ğŸ“ Sá»‘ cÃ¢u: {len(sentences)} | â±ï¸ Inference: {inference_time:.2f}s | ğŸµ Audio: {audio_duration:.2f}s | ğŸ“Š RTF: {rtf:.4f}"

        return (SAMPLE_RATE, audio_np), stats

    except Exception as e:
        return None, f"Lá»—i: {str(e)}"


# Create Gradio interface
with gr.Blocks(title="Vira-TTS Vietnamese", theme=gr.themes.Soft()) as demo: # type: ignore
    gr.Markdown("""
    # ğŸ™ï¸ Vira-TTS Vietnamese
    ### Text-to-Speech vá»›i Voice Cloning

    Upload má»™t file audio tham chiáº¿u Ä‘á»ƒ clone giá»ng nÃ³i, sau Ä‘Ã³ nháº­p vÄƒn báº£n Ä‘á»ƒ táº¡o audio.

    **Upsampler:** FlashSR (48kHz output, 14x realtime)
    """)

    with gr.Row():
        with gr.Column(scale=1):
            text_input = gr.Textbox(
                label="VÄƒn báº£n",
                placeholder="Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t táº¡i Ä‘Ã¢y...",
                lines=5
            )
            reference_audio = gr.Audio(
                label="Audio tham chiáº¿u (Ä‘á»ƒ clone giá»ng)",
                type="filepath"
            )
            generate_btn = gr.Button("ğŸµ Táº¡o Audio", variant="primary", size="lg")

        with gr.Column(scale=1):
            output_audio = gr.Audio(
                label="Audio Ä‘áº§u ra",
                type="numpy"
            )
            stats_output = gr.Textbox(
                label="Thá»‘ng kÃª",
                interactive=False
            )

    # Example texts (click to fill)
    gr.Markdown("### ğŸ“ VÃ­ dá»¥ vÄƒn báº£n:")
    with gr.Row():
        gr.Button("Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ áº£o.").click(
            fn=lambda: "Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ áº£o Vira-TTS.",
            outputs=[text_input]
        )
        gr.Button("Thá»i tiáº¿t hÃ´m nay").click(
            fn=lambda: "HÃ´m nay thá»i tiáº¿t ráº¥t Ä‘áº¹p, chÃºng ta Ä‘i dáº¡o nhÃ©!",
            outputs=[text_input]
        )
        gr.Button("CÃ´ng nghá»‡ AI").click(
            fn=lambda: "CÃ´ng nghá»‡ trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘ang phÃ¡t triá»ƒn ráº¥t nhanh chÃ³ng.",
            outputs=[text_input]
        )

    # Event handler
    generate_btn.click(
        fn=generate_speech,
        inputs=[text_input, reference_audio],
        outputs=[output_audio, stats_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)

